---
titulo: "Aula 08 ‚Äì Parte 03: Hands-on - Refatorando um C√≥digo de Data Science (Antes e Depois)"
modulo: "Engenharia de software para cientista de dados"
curso: "Engenharia de Machine Learning"
duracao_estimada_min: 30
prerequisitos:
  - "Python 3.12+"
  - "Aula 08 - Parte 02 conclu√≠da"
  - "Testes automatizados b√°sicos"
tags: ["hands-on", "refatoracao", "fastapi", "tests", "clean-code"]
---

# 1. Abertura do v√≠deo (script)

Ol√°! Espero que voc√™s estejam bem. Nessa aula vamos fazer uma refatora√ß√£o **na pr√°tica**.

Vamos pegar o c√≥digo real da nossa API de cr√©dito e identificar problemas t√≠picos: l√≥gica de neg√≥cio complexa dentro do servi√ßo, c√°lculo de score com m√∫ltiplas regras n√£o testadas isoladamente, e falta de separa√ß√£o entre feature engineering e predi√ß√£o. Vamos transform√°-lo em um c√≥digo organizado, test√°vel e pronto para produ√ß√£o.

# 2. Problema ‚Üí Agita√ß√£o ‚Üí Solu√ß√£o (Storytelling curto)

**Problema**: A fun√ß√£o `predict_one` em `model_service.py` tem 40+ linhas misturando c√°lculo de score, regras de neg√≥cio e decis√£o final.

**Agita√ß√£o**: Quando surge uma nova regra de neg√≥cio (ex: limite de empr√©stimo baseado em idade), precisamos mexer em uma fun√ß√£o gigante. Testar cada regra isoladamente √© imposs√≠vel.

**Solu√ß√£o**: Refatorar extraindo fun√ß√µes menores: `calculate_credit_score`, `apply_age_rules`, `apply_income_rules`. Cada uma test√°vel, reutiliz√°vel e com responsabilidade √∫nica.

# 3. Objetivos de aprendizagem

Ao final voc√™ ser√° capaz de:

1. **Refatorar** l√≥gica de neg√≥cio complexa em fun√ß√µes menores
2. **Extrair** c√°lculos de features para m√≥dulo separado
3. **Criar** testes unit√°rios para cada fun√ß√£o extra√≠da
4. **Comparar** estrutura original e refatorada

# 4. Pr√©-requisitos e Setup do Ambiente

**Requisitos:**
- Python 3.12+
- uv instalado
- Testes configurados

**Setup:**

```powershell
.\.venv\Scripts\Activate.ps1
uv run pytest -q
```

**Checklist de setup:**
- [ ] Ambiente virtual ativo
- [ ] Testes passando (todos os 8 testes)
- [ ] Git limpo (commit antes de refatorar)

# 5. Vis√£o geral do que j√° existe no projeto (continuidade)

Estado atual:
```
swe4ds-credit-api/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py      # Endpoint limpo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îî‚îÄ‚îÄ model_service.py # üî• Precisa refatorar
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_predict.py     # Testes de integra√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ test_health.py
‚îî‚îÄ‚îÄ logs/
```

**O que ser√° alterado nesta parte:**
- Refatorar `services/model_service.py`
- Criar `services/scoring.py` (novo)
- Criar `services/business_rules.py` (novo)
- Adicionar testes unit√°rios

# 6. Passo a passo (comandos + c√≥digo)

## Passo 1: Analisar o c√≥digo "antes" (Excalidraw: Slide 3)

**Inten√ß√£o:** Ver o problema antes da refatora√ß√£o.

Abra e analise o arquivo:

```powershell
code src/services/model_service.py
```

**Problemas identificados no c√≥digo atual:**

```python
def predict_one(data: dict) -> dict:
    """40+ linhas fazendo muita coisa!"""
    # 1. Extra√ß√£o de features
    age = data.get("age", 0)
    income = data.get("income", 0)
    loan_amount = data.get("loan_amount", 0)
    credit_history = data.get("credit_history", "poor")
    
    # 2. C√°lculo de score com m√∫ltiplas regras
    score = 0.5
    if credit_history == "good":
        score += 0.3
    elif credit_history == "fair":
        score += 0.1
    
    if age >= 25 and age <= 55:
        score += 0.1
    
    if income > loan_amount * 3:
        score += 0.2
    elif income > loan_amount * 2:
        score += 0.1
    
    # 3. Normaliza√ß√£o
    score = min(1.0, max(0.0, score))
    
    # 4. Decis√£o
    prediction = "approved" if score >= 0.6 else "rejected"
    
    return {"prediction": prediction, "confidence": round(score, 3)}
```

**CHECKPOINT:** Fun√ß√£o faz tudo: extra√ß√£o, c√°lculo, normaliza√ß√£o e decis√£o.

---

## Passo 2: Extract Function - Scoring por hist√≥rico (Excalidraw: Slide 3)

**Inten√ß√£o:** Isolar regras de hist√≥rico de cr√©dito.

Crie o novo m√≥dulo:

```powershell
New-Item src/services/scoring.py -ItemType File
code src/services/scoring.py
```

Adicione as fun√ß√µes extra√≠das:

```python
"""M√≥dulo de c√°lculo de score de cr√©dito."""


def score_by_credit_history(credit_history: str) -> float:
    """
    Calcula pontua√ß√£o baseada no hist√≥rico de cr√©dito.
    
    Args:
        credit_history: Hist√≥rico do cliente ('good', 'fair', 'poor')
        
    Returns:
        float: Pontos adicionados ao score (0.0 a 0.3)
    """
    if credit_history == "good":
        return 0.3
    elif credit_history == "fair":
        return 0.1
    return 0.0


def score_by_age(age: int) -> float:
    """
    Calcula pontua√ß√£o baseada na idade.
    
    Args:
        age: Idade do cliente
        
    Returns:
        float: Pontos adicionados ao score
    """
    if 25 <= age <= 55:
        return 0.1
    return 0.0


def score_by_income_ratio(income: float, loan_amount: float) -> float:
    """
    Calcula pontua√ß√£o baseada na rela√ß√£o renda/empr√©stimo.
    
    Args:
        income: Renda mensal
        loan_amount: Valor solicitado
        
    Returns:
        float: Pontos adicionados ao score
    """
    if income > loan_amount * 3:
        return 0.2
    elif income > loan_amount * 2:
        return 0.1
    return 0.0


def calculate_credit_score(data: dict) -> float:
    """
    Calcula score de cr√©dito completo.
    
    Args:
        data: Dicion√°rio com features do cliente
        
    Returns:
        float: Score final entre 0.0 e 1.0
    """
    base_score = 0.5
    
    score = base_score
    score += score_by_credit_history(data.get("credit_history", "poor"))
    score += score_by_age(data.get("age", 0))
    score += score_by_income_ratio(
        data.get("income", 0),
        data.get("loan_amount", 0)
    )
    
    # Normaliza entre 0 e 1
    return min(1.0, max(0.0, score))
```

**CHECKPOINT:** Fun√ß√µes pequenas, test√°veis e com responsabilidade √∫nica.

---

## Passo 3: Refatorar model_service.py (Excalidraw: Slide 4)

**Inten√ß√£o:** Simplificar a fun√ß√£o principal usando as novas fun√ß√µes.

Abra e edite:

```powershell
code src/services/model_service.py
```

```python
"""Servi√ßo de modelo de ML (simulado)."""

import json
import logging
from pathlib import Path

from src.services.scoring import calculate_credit_score

logger = logging.getLogger("credit-api")

# Caminho para logs de drift
DRIFT_LOG_PATH = Path("logs/input_samples.jsonl")

# Threshold de aprova√ß√£o
APPROVAL_THRESHOLD = 0.6


def load_model():
    """
    Carrega o modelo de ML.
    
    Nota: Por enquanto √© um modelo simulado.
    Em produ√ß√£o, carregaria um modelo real treinado.
    
    Returns:
        dict: Configura√ß√£o do modelo simulado
    """
    logger.info("Loading model...")
    return {
        "type": "simulated",
        "version": "0.1.0",
        "threshold": APPROVAL_THRESHOLD,
    }


def predict_one(data: dict) -> dict:
    """
    Realiza predi√ß√£o para um √∫nico registro.
    
    Args:
        data: Dicion√°rio com features do cliente
        
    Returns:
        dict: Resultado da predi√ß√£o
    """
    # Calcula score usando fun√ß√µes isoladas
    score = calculate_credit_score(data)
    
    # Decis√£o baseada no threshold
    prediction = "approved" if score >= APPROVAL_THRESHOLD else "rejected"
    
    return {
        "prediction": prediction,
        "confidence": round(score, 3),
    }


def log_input_sample(payload: dict) -> None:
    """
    Registra amostra de entrada para an√°lise de drift.
    
    Args:
        payload: Dados da requisi√ß√£o
    """
    try:
        DRIFT_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
        with DRIFT_LOG_PATH.open("a", encoding="utf-8") as f:
            f.write(json.dumps(payload) + "\n")
    except Exception as e:
        logger.warning(f"Failed to log input sample: {e}")


# Carrega modelo na inicializa√ß√£o do m√≥dulo
MODEL = load_model()
```

**CHECKPOINT:** `predict_one` agora tem 5 linhas limpas!

---

## Passo 4: Criar testes unit√°rios para scoring (Excalidraw: Slide 4)

**Inten√ß√£o:** Garantir que cada regra funciona isoladamente.

Crie os testes:

```powershell
New-Item tests/test_scoring.py -ItemType File
code tests/test_scoring.py
```

```python
"""Testes unit√°rios para m√≥dulo de scoring."""

from src.services.scoring import (
    calculate_credit_score,
    score_by_age,
    score_by_credit_history,
    score_by_income_ratio,
)


def test_score_by_credit_history_good():
    """Hist√≥rico bom retorna 0.3."""
    assert score_by_credit_history("good") == 0.3


def test_score_by_credit_history_fair():
    """Hist√≥rico regular retorna 0.1."""
    assert score_by_credit_history("fair") == 0.1


def test_score_by_credit_history_poor():
    """Hist√≥rico ruim retorna 0.0."""
    assert score_by_credit_history("poor") == 0.0


def test_score_by_age_in_range():
    """Idade na faixa ideal retorna 0.1."""
    assert score_by_age(30) == 0.1
    assert score_by_age(25) == 0.1
    assert score_by_age(55) == 0.1


def test_score_by_age_out_range():
    """Idade fora da faixa retorna 0.0."""
    assert score_by_age(20) == 0.0
    assert score_by_age(60) == 0.0


def test_score_by_income_ratio_high():
    """Renda > 3x empr√©stimo retorna 0.2."""
    assert score_by_income_ratio(10000, 3000) == 0.2


def test_score_by_income_ratio_medium():
    """Renda > 2x empr√©stimo retorna 0.1."""
    assert score_by_income_ratio(5000, 2000) == 0.1


def test_score_by_income_ratio_low():
    """Renda baixa retorna 0.0."""
    assert score_by_income_ratio(3000, 5000) == 0.0


def test_calculate_credit_score_best_case():
    """Melhor cen√°rio deve dar score alto."""
    data = {
        "age": 35,
        "income": 10000,
        "loan_amount": 2000,
        "credit_history": "good"
    }
    score = calculate_credit_score(data)
    assert score == 1.0  # 0.5 + 0.3 + 0.1 + 0.2


def test_calculate_credit_score_worst_case():
    """Pior cen√°rio deve dar score baixo."""
    data = {
        "age": 20,
        "income": 1000,
        "loan_amount": 5000,
        "credit_history": "poor"
    }
    score = calculate_credit_score(data)
    assert score == 0.5  # Apenas base score


def test_calculate_credit_score_medium():
    """Cen√°rio m√©dio."""
    data = {
        "age": 30,
        "income": 5000,
        "loan_amount": 2000,
        "credit_history": "fair"
    }
    score = calculate_credit_score(data)
    assert score == 0.8  # 0.5 + 0.1 + 0.1 + 0.1
```

**CHECKPOINT:** 13 testes unit√°rios cobrindo cada regra isoladamente!

---

## Passo 5: Validar que tudo funciona

**Inten√ß√£o:** Garantir que a refatora√ß√£o n√£o quebrou nada.

```powershell
# Rodar todos os testes
uv run pytest -v

# Deve mostrar:
# test_health.py::test_health_endpoint PASSED
# test_metrics.py::test_metrics_endpoint PASSED
# test_predict.py::test_predict_endpoint_with_valid_data PASSED
# test_predict.py::test_predict_endpoint_approved_scenario PASSED
# test_predict.py::test_predict_endpoint_rejected_scenario PASSED
# test_predict.py::test_predict_endpoint_with_invalid_age PASSED
# test_predict.py::test_predict_endpoint_with_invalid_credit_history PASSED
# test_predict.py::test_predict_endpoint_with_missing_field PASSED
# test_scoring.py::test_score_by_credit_history_good PASSED
# test_scoring.py::... (mais 12 testes)
```

**CHECKPOINT:** 21 testes passando! Refatora√ß√£o segura conclu√≠da.

---

## Passo 6: Compara√ß√£o Antes vs Depois (Excalidraw: Slide 5)

**Inten√ß√£o:** Visualizar ganhos de qualidade.

### ANTES:
```python
# model_service.py - 40+ linhas
def predict_one(data: dict) -> dict:
    age = data.get("age", 0)
    income = data.get("income", 0)
    loan_amount = data.get("loan_amount", 0)
    credit_history = data.get("credit_history", "poor")
    
    score = 0.5
    if credit_history == "good":
        score += 0.3
    # ... muitas linhas
    return {"prediction": prediction, "confidence": score}
```

- ‚ùå L√≥gica misturada
- ‚ùå Dif√≠cil testar isoladamente
- ‚ùå Mudan√ßas arriscadas

### DEPOIS:
```python
# model_service.py - 5 linhas
def predict_one(data: dict) -> dict:
    score = calculate_credit_score(data)
    prediction = "approved" if score >= APPROVAL_THRESHOLD else "rejected"
    return {"prediction": prediction, "confidence": round(score, 3)}

# scoring.py - Fun√ß√µes pequenas e test√°veis
def score_by_credit_history(credit_history: str) -> float:
    ...
```

- ‚úÖ Responsabilidades separadas
- ‚úÖ Cada regra testada isoladamente
- ‚úÖ F√°cil adicionar novas regras

**CHECKPOINT:** C√≥digo mais limpo, test√°vel e mant√≠vel.

# 7. Testes r√°pidos e valida√ß√£o

```powershell
# Rodar testes unit√°rios
uv run pytest tests/test_scoring.py -v

# Rodar todos os testes
uv run pytest -v

# Subir API e testar manualmente
uv run uvicorn src.main:app --reload
```

Teste manual via PowerShell:

```powershell
$body = @{
    age = 35
    income = 8000.0
    loan_amount = 2000.0
    credit_history = "good"
} | ConvertTo-Json

Invoke-RestMethod -Uri http://localhost:8000/predict -Method Post -Body $body -ContentType "application/json"
```

# 8. Observabilidade e boas pr√°ticas (mini-bloco)

1. **Fun√ß√µes pequenas**: cada uma com <10 linhas. Trade-off: mais arquivos, mas mais test√°vel.
2. **Single Responsibility**: cada fun√ß√£o faz uma coisa s√≥. Trade-off: mais fun√ß√µes, mas menor acoplamento.
3. **Testes unit√°rios r√°pidos**: rodam em <1s. Trade-off: esfor√ßo inicial, mas seguran√ßa cont√≠nua.
4. **Constantes expl√≠citas**: `APPROVAL_THRESHOLD` no topo. Trade-off: mais vari√°veis, mas configur√°vel.

# 9. Troubleshooting (erros comuns)

| Erro | Causa | Solu√ß√£o |
|------|-------|---------|
| `ModuleNotFoundError: No module named 'src.services.scoring'` | Import errado | Verificar caminho e __init__.py |
| Testes antigos falharam | Comportamento mudou | Revisar se l√≥gica est√° igual |
| Score diferente do esperado | Regras alteradas | Ajustar testes ou l√≥gica |
| Import circular | M√≥dulos se importando | Reorganizar depend√™ncias |

# 10. Exerc√≠cios (b√°sico e avan√ßado)

**B√°sico 1:** Adicionar nova regra: desconto de 0.05 se `age > 60`.
- Criar `score_by_senior` em `scoring.py`
- Adicionar teste unit√°rio
- Integrar em `calculate_credit_score`

**B√°sico 2:** Extrair valida√ß√µes de neg√≥cio para `business_rules.py`.
- Criar fun√ß√£o `validate_loan_eligibility`
- Validar se `income >= loan_amount * 0.3` (m√≠nimo 30%)
- Adicionar testes

**Avan√ßado:** Criar sistema de pesos configur√°vel.
- Substituir valores fixos (0.3, 0.2, etc) por um dict de configura√ß√£o
- Permitir ajustar pesos sem mudar c√≥digo
- Adicionar testes parametrizados

# 11. Resultados e Li√ß√µes

**Resultados (como medir):**
- Linhas por fun√ß√£o: de 40 para 5 em `predict_one`
- Cobertura de testes: de 0% para ~95% nas regras de score
- N√∫mero de fun√ß√µes test√°veis: de 1 para 5
- Tempo de adi√ß√£o de nova regra: de horas para minutos

**Li√ß√µes:**
- Refatora√ß√£o n√£o muda comportamento, melhora design
- Fun√ß√µes pequenas s√£o mais f√°ceis de entender e testar
- Separa√ß√£o de responsabilidades facilita evolu√ß√£o
- Testes unit√°rios d√£o confian√ßa para mudan√ßas

# 12. Encerramento e gancho para a pr√≥xima aula (script)

Nesta aula voc√™ realizou uma refatora√ß√£o pr√°tica real, transformando uma fun√ß√£o complexa de 40 linhas em m√≥dulos limpos e test√°veis, aumentando a cobertura de testes de forma significativa.

Na pr√≥xima parte, vamos aprender a **reorganizar o projeto completo** com uma estrutura profissional baseada no Cookiecutter Data Science, integrando nossa API refatorada em uma estrutura escal√°vel para produ√ß√£o.
